# Medical-VQA
This project fine-tunes advanced multimodal models, ViLT and BLIP-2, for medical Visual Question Answering (VQA) using the SLAKE dataset. It evaluates performance with F1 and Exact Match metrics, showcasing how LoRA fine-tuning and BLIP-2â€™s modular design outperform ViLT for domain-specific tasks.
